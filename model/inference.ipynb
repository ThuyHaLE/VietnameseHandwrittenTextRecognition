{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGU0IQ1Y7uw+WXIB46DkR4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbhIsrgUvOje","executionInfo":{"status":"ok","timestamp":1700501012639,"user_tz":-420,"elapsed":29173,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}},"outputId":"9245c700-da92-41da-f12f-51196bf720e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install -U scikit-image\n","!pip -q install einops\n","!pip -q install lmdb"]},{"cell_type":"code","source":["#Load model and weights\n","!gdown 1VU-qucVHcNbu2qnGkWWNwO0TRhY-7iH2\n","!unzip -q vietocr.zip\n","!unzip -q weights.zip\n","\n","#Import model\n","from vietocr import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LTZrtlcvULH","executionInfo":{"status":"ok","timestamp":1700501022503,"user_tz":-420,"elapsed":9975,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}},"outputId":"98cce778-3a57-46b3-e0fa-4d3566f982cf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1VU-qucVHcNbu2qnGkWWNwO0TRhY-7iH2\n","To: /content/vietocr.zip\n","100% 142M/142M [00:05<00:00, 25.2MB/s]\n"]}]},{"cell_type":"code","source":["#Load config\n","def load_config(yml_path):\n","  with open(yml_path, \"r\") as stream:\n","    try:\n","      config = yaml.safe_load(stream)\n","      return config\n","    except yaml.YAMLError as exc:\n","      print(exc)\n","\n","#Preprocessing\n","def remove_background(image):\n","  gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  # Remove horizontal lines\n","  horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40,1))\n","  remove_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)\n","  cnts = cv2.findContours(remove_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","  for c in cnts:\n","    cv2.drawContours(thresh, [c], -1, (0,255,255), 5)\n","  # Remove vertical lines\n","  vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,40))\n","  remove_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n","  cnts = cv2.findContours(remove_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","  for c in cnts:\n","    cv2.drawContours(thresh, [c], -1, (0,255,255), 15)\n","  contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","  bounding_boxes = []\n","  for cnt in contours:\n","    if cv2.contourArea(cnt)>50:\n","      [x,y,w,h] = cv2.boundingRect(cnt)\n","      if (x, y) != (0, 0) and (y+h-y)/image.shape[0] > 0.18 and (x+w-x)/image.shape[1] > 0.01 and (x+w-x)/(y+h-y) > 0.15:\n","        bounding_boxes.append([x,y,x+w,y+h])\n","  if np.array(bounding_boxes).size != 0:\n","    yymin = min(np.array(bounding_boxes)[:, 1])\n","    xxmax = max(np.array(bounding_boxes)[:, 2])\n","    yymax = max(np.array(bounding_boxes)[:, 3])\n","    xxmax = xxmax + 40 if xxmax + 40 < image.shape[1] else xxmax\n","    yymin = yymin - 5 if yymin - 5 > 0 else yymin\n","    yymax = yymax + 5 if yymax + 5 < image.shape[0] else yymax\n","    return image[yymin:yymax, 0:xxmax]\n","  else:\n","    return image\n","\n","#Inference\n","def prediction(img_path):\n","  img = cv2.imread(img_path)\n","  processed_img = remove_background(img)\n","  img = Image.fromarray(processed_img)\n","  s = detector.predict(img, return_prob = False)\n","  return s\n","\n","def predict(image_folder, output_file_path):\n","    prediction = pd.DataFrame(columns=['id', 'answer', 'elapsed_time'])\n","    index = 0\n","    for person_id in os.listdir(image_folder):\n","        for image_id in os.listdir(os.path.join(image_folder, person_id)):\n","            fp = os.path.join(image_folder, person_id, image_id)\n","            image_id = os.path.join(person_id, image_id)\n","            image = cv2.imread(fp)\n","\n","            # Start inference\n","            start = time.time()\n","            processed_img = remove_background(image) # preprocess\n","            img = Image.fromarray(processed_img)\n","            answer = s = detector.predict(img, return_prob = False) # infer\n","            answer = answer.replace('Đp', 'Đg').replace('đp', 'đg') # post process\n","            end = time.time()\n","\n","            prediction.loc[index] = [image_id, answer, end - start]\n","            index += 1\n","    # Write prediction\n","    prediction.to_csv(output_file_path, index=False)"],"metadata":{"id":"CPcmd84iwIAp","executionInfo":{"status":"ok","timestamp":1700501101762,"user_tz":-420,"elapsed":921,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Update config\n","config = load_config('/content/base.yml')\n","config['weights'] = '/content/weights/transformerocr.pth' #trained on our modified dataset\n","\n","#Load predictor\n","detector = Predictor(config)"],"metadata":{"id":"0PIBMfHwwCvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load publictest\n","!gdown 1b2_B1HsssTCFBtLMG9xzndxmygM3TLCF\n","!unzip public_test.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDu3vVUkxEY5","executionInfo":{"status":"ok","timestamp":1700501300465,"user_tz":-420,"elapsed":3943,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}},"outputId":"e2f65719-e273-4cdc-91f9-4789c95bfe0c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1b2_B1HsssTCFBtLMG9xzndxmygM3TLCF\n","To: /content/public_test.zip\n","100% 36.4M/36.4M [00:01<00:00, 27.4MB/s]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","predict(\"/content/public_test/images\", \"team_00_private_test_pred.csv\")"],"metadata":{"id":"EYa0Iw2nwRHc","executionInfo":{"status":"ok","timestamp":1700502416465,"user_tz":-420,"elapsed":399074,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["pd.read_csv('/content/team_00_private_test_pred.csv')[['id', 'answer']].to_csv('private_test_pred.csv', index = False)"],"metadata":{"id":"qySl29TA2tiG","executionInfo":{"status":"ok","timestamp":1700502687241,"user_tz":-420,"elapsed":533,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def check_modelsize(config):\n","  model, vocab = build_model(config)\n","  weights = config['weights']\n","  model.load_state_dict(torch.load(weights, map_location=torch.device(config['device'])))\n","  param_size = 0\n","  for param in model.parameters():\n","      param_size += param.nelement() * param.element_size()\n","  buffer_size = 0\n","  for buffer in model.buffers():\n","      buffer_size += buffer.nelement() * buffer.element_size()\n","  size_all_mb = (param_size + buffer_size) / 1024**2\n","  print('model size: {:.3f}MB'.format(size_all_mb))\n","\n","check_modelsize(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ek03rXDwSzG","executionInfo":{"status":"ok","timestamp":1700501447280,"user_tz":-420,"elapsed":2916,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}},"outputId":"1408e450-2527-4c5c-d579-f56c00f143ab"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["model size: 144.666MB\n"]}]}]}